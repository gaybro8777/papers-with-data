# Papers with Data
Data reigns supreme ðŸ¥‡. Every day it becomes more evident that *data* is the limiting factor for state-of-the-art ðŸ“ˆ machine learning. Your model architecture may be revolutionary, but without high-quality data ðŸ“Š, it will be doomed to mediocrity. Pair idea with execution and use top-notch data in your next project!

To make your life easier, we've combed through the **2359** papers accepted to CVPR in 2023 and compiled a short-list of papers introducing exciting new datasets.

## CVPR 2023 Papers

<!--- AUTOGENERATED_COURSES_TABLE -->
<!---
   WARNING: DO NOT EDIT THIS TABLE MANUALLY. IT IS AUTOMATICALLY GENERATED.
   HEAD OVER TO CONTRIBUTING.MD FOR MORE DETAILS ON HOW TO MAKE CHANGES PROPERLY.
-->
| **topic** | **tags** | **paper** | **dataset** | **code** |
|:---------:|:---------:|:---------:|:-----------:|:--------:|
| MVImgNet: A Large-scale Dataset of Multi-view Images | `multi-view`, `image` | [![arXiv](https://img.shields.io/badge/arXiv-2303.06042-b31b1b.svg)](https://arxiv.org/abs/2303.06042)| [![FiftyOne](https://img.shields.io/badge/FiftyOne-blue)](https://cvpr.fiftyone.ai/datasets/MVImgNet/samples) | [![GitHub](https://img.shields.io/github/stars/GAP-LAB-CUHK-SZ/MVImgNet?style=social)](https://github.com/GAP-LAB-CUHK-SZ/MVImgNet) |
| GeoNet: Benchmarking Unsupervised Adaptation across Geographies | `geolocation`, `image` | [![arXiv](https://img.shields.io/badge/arXiv-2303.15443-b31b1b.svg)](https://arxiv.org/abs/2303.15443)| [![FiftyOne](https://img.shields.io/badge/FiftyOne-blue)](https://cvpr.fiftyone.ai/datasets/GeoNet/samples) |  |
| Joint HDR Denoising and Fusion: A Real-World Mobile HDR Image Dataset | `denoising`, `image` | | [![FiftyOne](https://img.shields.io/badge/FiftyOne-blue)](https://cvpr.fiftyone.ai/datasets/Mobile-HDR/samples) | [![GitHub](https://img.shields.io/github/stars/shuaizhengliu/joint-hdrdn?style=social)](https://github.com/shuaizhengliu/joint-hdrdn) |
| Spring: A High-Resolution High-Detail Dataset and Benchmark for Scene Flow, Optical Flow and Stereo | `optical flow`, `stereo`, `image` | [![arXiv](https://img.shields.io/badge/arXiv-2303.01943-b31b1b.svg)](https://arxiv.org/abs/2303.01943)| [![FiftyOne](https://img.shields.io/badge/FiftyOne-blue)](https://cvpr.fiftyone.ai/datasets/Spring/samples) |  |
| ImageNet-E: Benchmarking Neural Network Robustness via Attribute Editing | `image`, `editing` | [![arXiv](https://img.shields.io/badge/arXiv-2303.17096-b31b1b.svg)](https://arxiv.org/abs/2303.17096)| [![FiftyOne](https://img.shields.io/badge/FiftyOne-blue)](https://cvpr.fiftyone.ai/datasets/ImageNet-E/samples) | [![GitHub](https://img.shields.io/github/stars/alibaba/easyrobust?style=social)](https://github.com/alibaba/easyrobust) |
| ARKitTrack: A New Diverse Dataset for Tracking Using Mobile RGB-D Data | `RGB-D`, `segmentation`, `video` | [![arXiv](https://img.shields.io/badge/arXiv-2303.13885-b31b1b.svg)](https://arxiv.org/abs/2303.13885)| [![FiftyOne](https://img.shields.io/badge/FiftyOne-blue)](https://cvpr.fiftyone.ai/datasets/ARKitTrack/samples) | [![GitHub](https://img.shields.io/github/stars/lawrence-cj/ARKitTrack?style=social)](https://github.com/lawrence-cj/ARKitTrack) |
| Diverse Embedding Expansion Network and Low-Light Cross-Modality Benchmark for Visible-Infrared Person Re-identification | `low-light`, `cross-modal`, `IR` | [![arXiv](https://img.shields.io/badge/arXiv-2303.14481-b31b1b.svg)](https://arxiv.org/abs/2303.14481)| [![FiftyOne](https://img.shields.io/badge/FiftyOne-blue)](https://cvpr.fiftyone.ai/datasets/LLCM/samples) | [![GitHub](https://img.shields.io/github/stars/ZYK100/LLCM?style=social)](https://github.com/ZYK100/LLCM) |
| JRDB-Pose: A Large-scale Dataset for Multi-Person Pose Estimation and Tracking | `pose estimation`, `image`, `keypoint`, `tracking` | [![arXiv](https://img.shields.io/badge/arXiv-2210.11940v2-b31b1b.svg)](https://arxiv.org/abs/2210.11940v2)| [![FiftyOne](https://img.shields.io/badge/FiftyOne-blue)](https://cvpr.fiftyone.ai/datasets/JRDB-Pose/samples) |  |
| A New Benchmark: On the Utility of Synthetic Data with Blender for Bare Supervised Learning and Downstream Domain Adaptation | `synthetic`, `domain adaptation`, `supervised` | [![arXiv](https://img.shields.io/badge/arXiv-2303.09165-b31b1b.svg)](https://arxiv.org/abs/2303.09165)| [![FiftyOne](https://img.shields.io/badge/FiftyOne-blue)](https://cvpr.fiftyone.ai/datasets/SynSL-120K/samples) | [![GitHub](https://img.shields.io/github/stars/huitangtang/On_the_Utility_of_Synthetic_Data?style=social)](https://github.com/huitangtang/On_the_Utility_of_Synthetic_Data) |
<!--- AUTOGENERATED_COURSES_TABLE -->

## ðŸ‘‹ Contributing
We would love your help in making this repository even better! If we missed a paper that introduced a new dataset, or if you can think of any ways to improve the repo, feel free to open an issue or a pull request!

## Note
This repository is inspired by [paperswithcode](https://paperswithcode.com/), and the template was adapted from [top-cvpr-2023-papers](https://github.com/SkalskiP/top-cvpr-2023-papers).
