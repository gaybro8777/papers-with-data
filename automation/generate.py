import base64
from glob import glob
from typing import List

import pandas as pd
from pandas.core.series import Series

README_PATH = "README.md"

BADGE_COLOR = "blue"
BADGE_TEXT = "FiftyOne"
LOGO_FILE = "assets/voxel51_logo.svg"

svg_data = open(LOGO_FILE, 'rb').read()
# Encode in base64 and decode it to ASCII
B64_LOGO = base64.b64encode(svg_data).decode('ascii')


# TOPIC_COLUMN_NAME = "topic"
TAGS_COLUMN_NAME = "tags"
TITLE_COLUMN_NAME = "title"
PAPER_COLUMN_NAME = "paper"
CODE_COLUMN_NAME = "code"
DATASET_COLUMN_NAME = "dataset"
DATASET_NAME_COLUMN_NAME = "dataset_name"


AUTOGENERATED_TABLE_TOKEN = "<!--- AUTOGENERATED_TABLE -->"

WARNING_HEADER = [
    "<!---",
    "   WARNING: DO NOT EDIT THIS TABLE MANUALLY. IT IS AUTOMATICALLY GENERATED.",
    "   HEAD OVER TO CONTRIBUTING.MD FOR MORE DETAILS ON HOW TO MAKE CHANGES PROPERLY.",
    "-->"
]

TABLE_HEADER = [
    "| **Title** | **Tags** | **Paper** | **Dataset** | **Code** |",
    "|:---------:|:---------:|:---------:|:-----------:|:--------:|"
]

GITHUB_CODE_PREFIX = "https://github.com/"
GITHUB_BADGE_PATTERN = "[![GitHub](https://img.shields.io/github/stars/{}?style=social)]({})"
DEFAULT_CODE_PATTERN = "[![Code Badge](https://img.shields.io/badge/Code-Code.svg)]({})"

ARXIV_BADGE_PATTERN = "[![arXiv](https://img.shields.io/badge/arXiv-{}-b31b1b.svg)](https://arxiv.org/abs/{})"
DEFAULT_PAPER_PATTERN = "[![Paper Badge](https://img.shields.io/badge/Paper-Paper.svg)]({})"

FIFTYONE_TRY_DATASET_PREFIX = "https://try.fiftyone.ai/datasets/"

FIFTYONE_DATASET_SUFFIX = "/samples"

FIFTYONE_BADGE_PATTERN = (
    f"[![{BADGE_TEXT}](https://img.shields.io/badge/{BADGE_TEXT}"
    f"-{BADGE_COLOR}.svg?logo=data:image/svg+xml;base64,{B64_LOGO})]"
    "({})"
)

NEURIPS_SECTION_HEADER = f"""
## NeurIPS 2023

We've combed through the **2384** papers accepted to NeurIPS in 2023 and compiled
a short-list of papers introducing exciting new datasets.
"""


CVPR_GIF = "![cvpr2023-4](https://github.com/voxel51/papers-with-data/assets/12500356/408fb4c6-3961-4909-a1a0-a756a8e8e6e8)"

CVPR_SECTION_HEADER = f"""
## CVPR 2023

{CVPR_GIF}

We've combed through the **2359** papers accepted to CVPR in 2023 and compiled
a short-list of papers introducing exciting new datasets.
"""

ICCV_SECTION_HEADER = """
## ICCV 2023

"""

WACV_SECTION_HEADER = """
## WACV 2024

"""

YEAR_SECTION_HEADER = """
## Papers from {}


"""


CLASSICS_SECTION_HEADER = """
## Classics


"""



def create_fiftyone_badge(url):
    return FIFTYONE_BADGE_PATTERN.format(url)

def read_lines_from_file(path: str) -> List[str]:
    ''' Reads lines from file and strips trailing whitespaces. '''
    with open(path) as file:
        return [line.rstrip() for line in file]

def save_lines_to_file(path: str, lines: List[str]) -> None:
    ''' Saves lines to file. '''
    with open(path, "w") as f:
        for line in lines:
            f.write("%s\n" % line)

def format_tags(tags):
    tags = tags.split(",")
    tags = [f"`{tag.strip()}`" for tag in tags]
    return ", ".join(tags)

def format_entry(data_file, entry: Series) -> str:
    ''' Formats entry into markdown table row. '''
    tags = format_tags(entry.loc[TAGS_COLUMN_NAME])
    title = entry.loc[TITLE_COLUMN_NAME]
    paper_url = entry.loc[PAPER_COLUMN_NAME]
    code_url = entry.loc[CODE_COLUMN_NAME]
    if type(code_url) == float:
        code_url = ""
    dataset_url = entry.loc[DATASET_COLUMN_NAME]
    if type(dataset_url) == float:
        dataset_url = ""
    if type(paper_url) == float:
        paper_url = ""
    
    prefix = FIFTYONE_TRY_DATASET_PREFIX
    dataset_url = prefix + dataset_url + FIFTYONE_DATASET_SUFFIX if dataset_url else ""
    dataset_url = dataset_url.replace(" ", "%20")
    
    fiftyone_badge = FIFTYONE_BADGE_PATTERN.format(dataset_url) if dataset_url else ""
    
    if "github" in code_url:
        stripped_code_url = code_url.replace(GITHUB_CODE_PREFIX, "")
        code_badge = GITHUB_BADGE_PATTERN.format(stripped_code_url, code_url) if code_url else ""
    else:
        code_badge = DEFAULT_CODE_PATTERN.format(code_url) if code_url else ""
    
    if ":" in paper_url:
        paper_badge = DEFAULT_PAPER_PATTERN.format(paper_url)
    else:
        paper_badge = ARXIV_BADGE_PATTERN.format(paper_url, paper_url) if paper_url else ""
    return f"| {title} | {tags} | {paper_badge}| {fiftyone_badge} | {code_badge} |"


def load_table_entries(path: str) -> List[str]:
    ''' Loads table entries from csv file. '''
    df = pd.read_csv(path,  quotechar='"', dtype=str)
    df.columns = df.columns.str.strip()
    return [
        format_entry(path, row)
        for _, row
        in df.iterrows()
    ]


def search_lines_with_token(lines: List[str], token: str) -> List[int]:
    ''' Searches for lines with token. '''
    result = []
    for line_index, line in enumerate(lines):
        if token in line:
            result.append(line_index)
    return result


def inject_markdown_tables_into_readme(readme_lines: List[str], table_lines: List[str]) -> List[str]:
    ''' Injects markdown tables into readme. '''
    lines_with_token_indexes = search_lines_with_token(lines=readme_lines, token=AUTOGENERATED_TABLE_TOKEN)
    if len(lines_with_token_indexes) != 2:
        raise Exception(f"Please inject two {AUTOGENERATED_TABLE_TOKEN} "
                        f"tokens to signal start and end of autogenerated table.")

    [table_start_line_index, table_end_line_index] = lines_with_token_indexes
    return readme_lines[:table_start_line_index + 1] + table_lines + readme_lines[table_end_line_index:]


def generate_section_header(data_file):
    if "neurips" in data_file:
        return NEURIPS_SECTION_HEADER
    elif "cvpr" in data_file:
        return CVPR_SECTION_HEADER
    elif "iccv" in data_file:
        return ICCV_SECTION_HEADER
    elif "wacv" in data_file:
        return WACV_SECTION_HEADER
    elif "2" in data_file:
        year = ''.join([char for char in data_file if char.isdigit()])
        return YEAR_SECTION_HEADER.format(year)
    else:
        return CLASSICS_SECTION_HEADER

PATH = "automation/data/"
DATA_FILES = (
    "neurips_2023_papers.csv",
    "wacv_2024_papers.csv",
    "iccv_2023_papers.csv",
    "cvpr_2023_papers.csv",
    # "papers_with_data_2023.csv",
    "papers_with_data_2022.csv",
    "papers_with_data_classic.csv",
)

DATA_FILES = [PATH + data_file for data_file in DATA_FILES]


def generate_tables():
    table_lines = []
    data_files = DATA_FILES
    for data_file in data_files:
        table_lines += [generate_section_header(data_file)]
        table_lines += ["\n\n"] + TABLE_HEADER
        table_lines += load_table_entries(data_file)
    table_lines = WARNING_HEADER + table_lines
    return table_lines


def generate_readme():
    readme_path = README_PATH
    table_lines = generate_tables()
    readme_lines = read_lines_from_file(readme_path)
    readme_lines = inject_markdown_tables_into_readme(
        readme_lines=readme_lines, 
        table_lines=table_lines
        )
    save_lines_to_file(path=readme_path, lines=readme_lines)


if __name__ == "__main__":
    generate_readme()
